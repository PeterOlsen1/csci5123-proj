{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71b58a7e",
   "metadata": {},
   "source": [
    "# Item-Item\n",
    "\n",
    "This file is an extension of the previously existing recommender system that we have replicated. In this, we will add an extra layer of recommendation through an item-item algorithm, with access to song features from the spotify 1m song dataset.\n",
    "\n",
    "While it does not contain a ton of song data, it has tag data on roughly ~50,000 popular songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd5d632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da2dd759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read song info and create a mapping between spotify id and index\n",
    "song_info = pd.read_csv('data/Music Info.csv')\n",
    "uri_to_idx = {}\n",
    "for i, row in song_info.iterrows():\n",
    "    uri_to_idx[row[\"spotify_id\"]] = i\n",
    "\n",
    "# metrics = ['danceability', 'energy', 'speechiness', 'acousticness', \n",
    "#            'instrumentalness','liveness', 'valence']\n",
    "# skipping text data & year & duration\n",
    "song_features = song_info.iloc[:, 9:].head(10000)\n",
    "\n",
    "# not every feature is 0-1, use a scaler to normalize\n",
    "scaler = StandardScaler()\n",
    "song_features = pd.DataFrame(scaler.fit_transform(song_features))\n",
    "correlation = song_features.T.corr(method='pearson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd5d23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_songs(uri, n=10):\n",
    "    if uri.startswith(\"spotify:track:\"):\n",
    "        uri = uri[14:]\n",
    "\n",
    "    if uri not in uri_to_idx:\n",
    "        return None\n",
    "    \n",
    "    idx = uri_to_idx[uri]\n",
    "    if idx > 10000:\n",
    "        return None\n",
    "\n",
    "    best = correlation.iloc[idx].nlargest(n + 1).drop(index=idx)\n",
    "    return best\n",
    "\n",
    "def interpret_best(best):\n",
    "    return [(song_info.iloc[i][\"name\"], song_info.iloc[i][\"artist\"], best[i]) for i in best.index]\n",
    "\n",
    "def get_batch_similarity(uris, n=10):\n",
    "    '''\n",
    "    Get the similarity for multiple songs and merge them into one\n",
    "    '''\n",
    "    total = {}\n",
    "    for uri in uris:\n",
    "        best = get_similar_songs(uri, n)\n",
    "\n",
    "        if best is None:\n",
    "            continue\n",
    "\n",
    "        for i in best.index:\n",
    "            if i not in total:\n",
    "                total[i] = 0\n",
    "            total[i] += best[i]\n",
    "\n",
    "    total = pd.Series(total).nlargest(n)\n",
    "    return total\n",
    "\n",
    "# display(interpret_best(get_batch_similarity([\"0ayaHJBfEV8cyVQsncW1eL\"], 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afbaff8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Communication Breakdown', 'Led Zeppelin', 0.9654537527578801),\n",
       " ('That Was a Crazy Game of Poker', 'O.A.R.', 0.9403363290618125),\n",
       " (\"It's Warmer In The Basement\", 'Cobra Starship', 0.9399971371421316),\n",
       " (\"Don't Stop Me Now\", 'Queen', 0.9317897153291339),\n",
       " ('Put Your Dukes Up John', 'Arctic Monkeys', 0.9301100866668613),\n",
       " ('Valley Of The Damned', 'DragonForce', 0.9155778059800774),\n",
       " ('Vodka', 'Korpiklaani', 0.913994476705551),\n",
       " ('The Love Song', 'Marilyn Manson', 0.8990980667394093),\n",
       " (\"You Can't Stop Me\", 'Guano Apes', 0.8977336151552145),\n",
       " ('Bulls on Parade', 'Rage Against the Machine', 0.8928456813460827)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fp = open('submission.hdf')\n",
    "line = fp.readline()\n",
    "tracks = list(map(lambda x: x[1:], line.split(\",\")))[1:]\n",
    "fp.close()\n",
    "\n",
    "display(interpret_best(get_batch_similarity(tracks, 10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci5123-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
