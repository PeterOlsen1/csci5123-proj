{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:18:18.905289Z",
     "start_time": "2018-07-01T15:18:18.899944Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:18:19.302277Z",
     "start_time": "2018-07-01T15:18:18.907606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterolsen/.pyenv/versions/csci5123-proj/lib/python3.10/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "CYTHON_DTYPE = np.float32\n",
    "ID_DTYPE = np.int32\n",
    "\n",
    "from typing import Tuple, Union, Dict\n",
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "\n",
    "# Set of global variables for multiprocessing\n",
    "_user_repr = np.array([])   # n_users, n_features\n",
    "_user_repr_biases = np.array([])\n",
    "_item_repr = np.ndarray([])  # n_features, n_items\n",
    "_item_repr_biases = np.array([])\n",
    "_pool = None\n",
    "_item_chunks = {}\n",
    "\n",
    "\n",
    "def _check_setup():\n",
    "    if not (len(_user_repr)\n",
    "        and len(_user_repr_biases)\n",
    "        and len(_item_repr)\n",
    "        and len(_item_repr_biases)):\n",
    "\n",
    "        raise EnvironmentError('You must setup mode.batch_setup(item_ids) before using predict')\n",
    "\n",
    "\n",
    "def _batch_setup(model: LightFM,\n",
    "                 item_chunks: Dict[int, np.ndarray],\n",
    "                 item_features: Union[None, sp.csr_matrix]=None,\n",
    "                 user_features: Union[None, sp.csr_matrix]=None,\n",
    "                 n_process: int=1):\n",
    "\n",
    "    global _item_repr, _user_repr\n",
    "    global _item_repr_biases, _user_repr_biases\n",
    "    global _pool\n",
    "    global _item_chunks\n",
    "\n",
    "    if item_features is None:\n",
    "        n_items = len(model.item_biases)\n",
    "        item_features = sp.identity(n_items, dtype=CYTHON_DTYPE, format='csr')\n",
    "\n",
    "    if user_features is None:\n",
    "        n_users = len(model.user_biases)\n",
    "        user_features = sp.identity(n_users, dtype=CYTHON_DTYPE, format='csr')\n",
    "\n",
    "    n_users = user_features.shape[0]\n",
    "    user_features = model._construct_user_features(n_users, user_features)\n",
    "    _user_repr, _user_repr_biases = _precompute_representation(\n",
    "        features=user_features,\n",
    "        feature_embeddings=model.user_embeddings,\n",
    "        feature_biases=model.user_biases,\n",
    "    )\n",
    "\n",
    "    n_items = item_features.shape[0]\n",
    "    item_features = model._construct_item_features(n_items, item_features)\n",
    "    _item_repr, _item_repr_biases = _precompute_representation(\n",
    "        features=item_features,\n",
    "        feature_embeddings=model.item_embeddings,\n",
    "        feature_biases=model.item_biases,\n",
    "    )\n",
    "    _item_repr = _item_repr.T\n",
    "    _item_chunks = item_chunks\n",
    "    _clean_pool()\n",
    "    # Pool creation should go last\n",
    "    if n_process > 1:\n",
    "        _pool = mp.Pool(processes=n_process)\n",
    "\n",
    "\n",
    "def _precompute_representation(\n",
    "        features: sp.csr_matrix,\n",
    "        feature_embeddings: np.ndarray,\n",
    "        feature_biases: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    :param: features           csr_matrix         [n_objects, n_features]\n",
    "    :param: feature_embeddings np.ndarray(float)  [n_features, no_component]\n",
    "    :param: feature_biases     np.ndarray(float)  [n_features]\n",
    "\n",
    "    :return:\n",
    "    TODO:\n",
    "    tuple of\n",
    "    - representation    np.ndarray(float)  [n_objects, no_component+1]\n",
    "    - bias repr\n",
    "    \"\"\"\n",
    "\n",
    "    representation = features.dot(feature_embeddings)\n",
    "    representation_bias = features.dot(feature_biases)\n",
    "    return representation, representation_bias\n",
    "\n",
    "\n",
    "def _get_top_k_scores(scores: np.ndarray, k: int, item_ids: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    :return: indices of items, top_k scores. All in score decreasing order.\n",
    "    \"\"\"\n",
    "\n",
    "    if k:\n",
    "        top_indices = np.argpartition(scores, -k)[-k:]\n",
    "        scores = scores[top_indices]\n",
    "        sorted_top_indices = np.argsort(-scores)\n",
    "        scores = scores[sorted_top_indices]\n",
    "        top_indices = top_indices[sorted_top_indices]\n",
    "    else:\n",
    "        top_indices = np.arange(len(scores))\n",
    "\n",
    "    if len(item_ids):\n",
    "        top_indices = item_ids[top_indices]\n",
    "\n",
    "    return top_indices, scores\n",
    "\n",
    "\n",
    "def _batch_predict_for_user(user_id: int, top_k: int=50, chunk_id: int=None, item_ids=None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    :return: indices of items, top_k scores. All in score decreasing order.\n",
    "    \"\"\"\n",
    "    # exclude biases from repr (last column of user_repr and last row of transposed item repr)\n",
    "    user_repr = _user_repr[user_id, :]\n",
    "\n",
    "    if chunk_id is not None:\n",
    "        item_ids = _item_chunks[chunk_id]\n",
    "    elif item_ids is None:\n",
    "        raise UserWarning('Supply item chunks at setup or item_ids in predict')\n",
    "\n",
    "    if item_ids is None or len(item_ids) == 0:\n",
    "        item_repr = _item_repr\n",
    "        item_repr_biases = _item_repr_biases\n",
    "    else:\n",
    "        item_repr = _item_repr[:, item_ids]\n",
    "        item_repr_biases = _item_repr_biases[item_ids]\n",
    "\n",
    "    scores = user_repr.dot(item_repr)\n",
    "    scores += _user_repr_biases[user_id]\n",
    "    scores += item_repr_biases\n",
    "    return _get_top_k_scores(scores, k=top_k, item_ids=item_ids)\n",
    "\n",
    "\n",
    "def _clean_pool():\n",
    "    global _pool\n",
    "    if _pool is not None:\n",
    "        _pool.close()\n",
    "        _pool = None\n",
    "\n",
    "\n",
    "def _batch_cleanup():\n",
    "    global _item_ids, _item_repr, _user_repr, _pool, _item_chunks\n",
    "    _item_chunks = {}\n",
    "    _user_repr = np.array([])\n",
    "    _item_repr = np.ndarray([])\n",
    "    _clean_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILL IN MISSING CODE FROM https://github.com/dmitryhd/lightfm\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "class LightFMWrapper(LightFM):\n",
    "    def __init__(self, no_components, loss, learning_rate, max_sampled, random_state, user_alpha):\n",
    "        super().__init__(no_components=200, loss='warp', learning_rate=0.02, max_sampled=400, random_state=1, user_alpha=1e-05)\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_cython_dtype(mat):\n",
    "        if mat.dtype != CYTHON_DTYPE:\n",
    "            return mat.astype(CYTHON_DTYPE)\n",
    "        else:\n",
    "            return mat\n",
    "\n",
    "    def _construct_item_features(self, n_items: int, item_features) -> sp.csr_matrix:\n",
    "        # TODO: mb. merge with user features\n",
    "        if item_features is None:\n",
    "            item_features = sp.identity(n_items, dtype=CYTHON_DTYPE, format='csr')\n",
    "        else:\n",
    "            item_features = item_features.tocsr()\n",
    "\n",
    "        if n_items > item_features.shape[0]:\n",
    "            raise Exception('Number of item feature rows does not equal the number of items')\n",
    "\n",
    "        if self.item_embeddings is not None:\n",
    "            if not self.item_embeddings.shape[0] >= item_features.shape[1]:\n",
    "                raise ValueError(\n",
    "                    'The item feature matrix specifies more features than there are estimated '\n",
    "                    'feature embeddings: {} vs {}.'.format(self.item_embeddings.shape[0], item_features.shape[1])\n",
    "                )\n",
    "\n",
    "        item_features = self._to_cython_dtype(item_features)\n",
    "        return item_features\n",
    "    \n",
    "    def batch_setup(self, item_chunks, item_features, user_features, n_process: int=1):\n",
    "\n",
    "        global _item_repr, _user_repr\n",
    "        global _item_repr_biases, _user_repr_biases\n",
    "        global _pool\n",
    "        global _item_chunks\n",
    "\n",
    "        self.n_process = n_process\n",
    "\n",
    "        if item_features is None:\n",
    "            n_items = len(self.item_biases)\n",
    "            item_features = sp.identity(n_items, dtype=CYTHON_DTYPE, format='csr')\n",
    "\n",
    "        if user_features is None:\n",
    "            n_users = len(self.user_biases)\n",
    "            user_features = sp.identity(n_users, dtype=CYTHON_DTYPE, format='csr')\n",
    "\n",
    "        n_users = user_features.shape[0]\n",
    "        user_features = self._construct_user_features(n_users, user_features)\n",
    "        _user_repr, _user_repr_biases = _precompute_representation(\n",
    "            features=user_features,\n",
    "            feature_embeddings=self.user_embeddings,\n",
    "            feature_biases=self.user_biases,\n",
    "        )\n",
    "\n",
    "        n_items = item_features.shape[0]\n",
    "        item_features = self._construct_item_features(n_items, item_features)\n",
    "        _item_repr, _item_repr_biases = _precompute_representation(\n",
    "            features=item_features,\n",
    "            feature_embeddings=self.item_embeddings,\n",
    "            feature_biases=self.item_biases,\n",
    "        )\n",
    "        _item_repr = _item_repr.T\n",
    "        _item_chunks = item_chunks\n",
    "        # _clean_pool()\n",
    "        # # Pool creation should go last\n",
    "        # if n_process > 1:\n",
    "        #     _pool = mp.Pool(processes=n_process)\n",
    "    \n",
    "    def batch_predict(self, chunk_id, user_ids, top_k: int=50):\n",
    "        # from lightfm.inference import _batch_predict_for_user, _check_setup, _pool, _item_chunks\n",
    "\n",
    "        self._check_initialized()\n",
    "        # print(_item_chunks)\n",
    "        print('Batch predict: user_ids: {:,}, item_ids: {:,}'.format(len(user_ids), len(_item_chunks[chunk_id])))\n",
    "\n",
    "        recommendations = {}\n",
    "        if not isinstance(user_ids, np.ndarray):\n",
    "            user_ids = np.array(user_ids, dtype=ID_DTYPE)\n",
    "\n",
    "        # _check_setup()\n",
    "        btime = time.time()\n",
    "\n",
    "        if self.n_process == 1:\n",
    "            print('Start recommending: using single process')\n",
    "            # self.debug('Start recommending: using single process')\n",
    "            for user_id in user_ids:\n",
    "                rec_ids, scores = _batch_predict_for_user(user_id=user_id, top_k=top_k, chunk_id=chunk_id)\n",
    "                recommendations[user_id] = rec_ids, scores\n",
    "        else:\n",
    "            # self.debug('Start recommending: using multiprocessing')\n",
    "            print('Start recommending: using multiprocessing')\n",
    "            recs_list = _pool.starmap(\n",
    "                _batch_predict_for_user,\n",
    "                zip(user_ids, itertools.repeat(top_k), itertools.repeat(chunk_id)),\n",
    "            )\n",
    "            recommendations = dict(zip(user_ids, recs_list))\n",
    "\n",
    "        elapsed_sec = time.time() - btime\n",
    "        elapsed_sec_by_user = elapsed_sec / len(user_ids)\n",
    "        print('Recommendations for chunk {:,} done in {:.3f}s. {:.4f} s by user'.format(\n",
    "            chunk_id, elapsed_sec, elapsed_sec_by_user,\n",
    "        ))\n",
    "        return recommendations\n",
    "\n",
    "\n",
    "    def _construct_user_features(self, n_users, user_features):\n",
    "        if user_features is None:\n",
    "            user_features = sp.identity(n_users, dtype=CYTHON_DTYPE, format='csr')\n",
    "        else:\n",
    "            user_features = user_features.tocsr()\n",
    "\n",
    "        if n_users > user_features.shape[0]:\n",
    "            raise Exception('Number of user feature rows does not equal the number of users')\n",
    "\n",
    "        # If we already have embeddings, verify that\n",
    "        # we have them for all the supplied features\n",
    "        if self.user_embeddings is not None:\n",
    "            if not self.user_embeddings.shape[0] >= user_features.shape[1]:\n",
    "                raise ValueError(\n",
    "                    'The user feature matrix specifies more features than there are estimated '\n",
    "                    'feature embeddings: {} vs {}.'.format(self.user_embeddings.shape[0], user_features.shape[1])\n",
    "                )\n",
    "\n",
    "        user_features = self._to_cython_dtype(user_features)\n",
    "        return user_features\n",
    "    \n",
    "    def batch_cleanup(self):\n",
    "        _batch_cleanup()\n",
    "\n",
    "def _precompute_representation(features, feature_embeddings, feature_biases):\n",
    "    representation = features.dot(feature_embeddings)\n",
    "    representation_bias = features.dot(feature_biases)\n",
    "    return representation, representation_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:18:19.416728Z",
     "start_time": "2018-07-01T15:18:19.304010Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:18:24.568879Z",
     "start_time": "2018-07-01T15:18:19.418444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collaborative</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>modified_at</th>\n",
       "      <th>name</th>\n",
       "      <th>num_albums</th>\n",
       "      <th>num_artists</th>\n",
       "      <th>num_edits</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>4007017</td>\n",
       "      <td>1470355200</td>\n",
       "      <td>Funk</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>5823244</td>\n",
       "      <td>1412985600</td>\n",
       "      <td>Childhood</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>4891462</td>\n",
       "      <td>1421971200</td>\n",
       "      <td>Old Country</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>10002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>3498401</td>\n",
       "      <td>1492646400</td>\n",
       "      <td>april showers</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>10003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>8765977</td>\n",
       "      <td>1496534400</td>\n",
       "      <td>DnB</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>10004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>False</td>\n",
       "      <td>30149399</td>\n",
       "      <td>1509408000</td>\n",
       "      <td>EdM</td>\n",
       "      <td>124</td>\n",
       "      <td>87</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>100995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>False</td>\n",
       "      <td>71434251</td>\n",
       "      <td>1505520000</td>\n",
       "      <td>EME</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>100996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>False</td>\n",
       "      <td>13524857</td>\n",
       "      <td>1428796800</td>\n",
       "      <td>run!</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>100997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>False</td>\n",
       "      <td>3875542</td>\n",
       "      <td>1453680000</td>\n",
       "      <td>driving</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>100998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>False</td>\n",
       "      <td>20725278</td>\n",
       "      <td>1505260800</td>\n",
       "      <td>panic!</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>100999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      collaborative  duration_ms  modified_at           name  num_albums  \\\n",
       "0             False      4007017   1470355200           Funk          15   \n",
       "1             False      5823244   1412985600      Childhood          19   \n",
       "2             False      4891462   1421971200    Old Country          19   \n",
       "3             False      3498401   1492646400  april showers          14   \n",
       "4             False      8765977   1496534400            DnB          21   \n",
       "...             ...          ...          ...            ...         ...   \n",
       "4995          False     30149399   1509408000            EdM         124   \n",
       "4996          False     71434251   1505520000            EME          31   \n",
       "4997          False     13524857   1428796800           run!          40   \n",
       "4998          False      3875542   1453680000        driving          15   \n",
       "4999          False     20725278   1505260800         panic!          40   \n",
       "\n",
       "      num_artists  num_edits  num_followers  num_tracks     pid  \n",
       "0              11          4              1          16   10000  \n",
       "1              14          3              1          28   10001  \n",
       "2              12          3              1          23   10002  \n",
       "3              14          6              1          14   10003  \n",
       "4              14          6              1          31   10004  \n",
       "...           ...        ...            ...         ...     ...  \n",
       "4995           87         75              2         135  100995  \n",
       "4996           12         17              3         210  100996  \n",
       "4997           31         11              1          46  100997  \n",
       "4998           15          6              1          15  100998  \n",
       "4999           25         14              1          93  100999  \n",
       "\n",
       "[5000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load all datasets using the function\n",
    "df_tracks = pd.read_hdf('df_data/df_tracks.hdf', 'abc')\n",
    "df_playlists = pd.read_hdf('df_data/df_playlists.hdf', 'abc')\n",
    "df_playlists_info = pd.read_hdf('df_data/df_playlists_info.hdf', 'abc')\n",
    "df_playlists_test = pd.read_hdf('df_data/df_playlists_test.hdf', 'abc')\n",
    "df_playlists_test_info = pd.read_hdf('df_data/df_playlists_test_info.hdf', 'abc')\n",
    "\n",
    "# display(df_tracks)\n",
    "display(df_playlists_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:18:26.017140Z",
     "start_time": "2018-07-01T15:18:24.571608Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_hdf('df_data/train.hdf')\n",
    "val = pd.read_hdf('df_data/val1.hdf')\n",
    "val1_pids = joblib.load('df_data/val1_pids.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:19:30.909951Z",
     "start_time": "2018-07-01T15:18:26.018943Z"
    }
   },
   "outputs": [],
   "source": [
    "user_seen = train.groupby('pid').tid.apply(set).to_dict()\n",
    "val_tracks = val.groupby('pid').tid.apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>num_holdouts</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>num_tracks</th>\n",
       "      <th>pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disney</td>\n",
       "      <td>89</td>\n",
       "      <td>100</td>\n",
       "      <td>189</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indie Electro</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "      <td>165</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vibes</td>\n",
       "      <td>125</td>\n",
       "      <td>100</td>\n",
       "      <td>225</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indie</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "      <td>165</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>woo</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NEW YEARS</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>JESUS</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>yep</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Sad Music</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  num_holdouts  num_samples  num_tracks   pid\n",
       "0           disney            89          100         189  1000\n",
       "1    Indie Electro            65          100         165  1001\n",
       "2                              7            0          17  1002\n",
       "3            vibes           125          100         225  1003\n",
       "4            Indie            65          100         165  1004\n",
       "..             ...           ...          ...         ...   ...\n",
       "995            woo           146            0         146  1995\n",
       "996     NEW YEARS             38            0          38  1996\n",
       "997          JESUS            40            0          40  1997\n",
       "998            yep            29            0          29  1998\n",
       "999     Sad Music             16            0          16  1999\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_playlists_test_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:19:30.943469Z",
     "start_time": "2018-07-01T15:19:30.912781Z"
    }
   },
   "outputs": [],
   "source": [
    "num_playlists = len(train.pid) + 1\n",
    "\n",
    "config = {\n",
    "    'num_playlists': num_playlists + 1,\n",
    "    'num_tracks': df_tracks.tid.max() + 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:19:31.867927Z",
     "start_time": "2018-07-01T15:19:30.946052Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = sp.coo_matrix(\n",
    "    (np.ones(len(train)), (train.pid, train.tid)),\n",
    "    shape=(config['num_playlists'], config['num_tracks'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:19:31.872173Z",
     "start_time": "2018-07-01T15:19:31.869738Z"
    }
   },
   "outputs": [],
   "source": [
    "config['model_path'] = 'models/lightfm_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:30:18.392092Z",
     "start_time": "2018-07-01T15:19:31.873766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "Batch predict: user_ids: 992, item_ids: 113,331\n",
      "Start recommending: using single process\n",
      "Recommendations for chunk 0 done in 11.895s. 0.0120 s by user\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LightFMWrapper' object has no attribute 'batch_cleanup'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mbatch_setup(\n\u001b[1;32m     10\u001b[0m     item_chunks\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m: np\u001b[38;5;241m.\u001b[39marange(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_tracks\u001b[39m\u001b[38;5;124m'\u001b[39m])},\n\u001b[1;32m     11\u001b[0m     item_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     user_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     n_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m res \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbatch_predict(chunk_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, user_ids\u001b[38;5;241m=\u001b[39mval1_pids, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_cleanup\u001b[49m()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# model.fit(X_train, epochs=5, num_threads=6)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# res = model.predict(user_ids=val1_pids, item_ids=np.arange(config['num_tracks']))\u001b[39;00m\n\u001b[1;32m     22\u001b[0m score \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LightFMWrapper' object has no attribute 'batch_cleanup'"
     ]
    }
   ],
   "source": [
    "model = LightFMWrapper(no_components=200, loss='warp', learning_rate=0.02, max_sampled=400, random_state=1, user_alpha=1e-05)\n",
    "\n",
    "best_score = 0\n",
    "for i in range(60):\n",
    "    print(f'iteration: {i}')\n",
    "    \n",
    "    model.fit_partial(X_train, epochs=1, num_threads=8)\n",
    "\n",
    "    model.batch_setup(\n",
    "        item_chunks={0: np.arange(config['num_tracks'])},\n",
    "        item_features=None,\n",
    "        user_features=None,\n",
    "        n_process=1, \n",
    "    )\n",
    "\n",
    "    res = model.batch_predict(chunk_id=0, user_ids=val1_pids, top_k=600)\n",
    "    model.batch_cleanup()\n",
    "\n",
    "    # model.fit(X_train, epochs=5, num_threads=6)\n",
    "    # res = model.predict(user_ids=val1_pids, item_ids=np.arange(config['num_tracks']))\n",
    "    \n",
    "    score = []\n",
    "    for pid in val1_pids:\n",
    "        tracks_t = val_tracks[pid]\n",
    "        tracks = [i for i in res[pid][0] if i not in user_seen.get(pid, set())][:len(tracks_t)]\n",
    "        guess = np.sum([i in tracks_t for i in tracks])\n",
    "        score.append(guess / len(tracks_t))\n",
    "    \n",
    "    score = np.mean(score)\n",
    "    print(score)\n",
    "    if score > best_score:\n",
    "        joblib.dump(model, open(config['model_path'], 'wb'))\n",
    "        best_score = score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci5123-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
